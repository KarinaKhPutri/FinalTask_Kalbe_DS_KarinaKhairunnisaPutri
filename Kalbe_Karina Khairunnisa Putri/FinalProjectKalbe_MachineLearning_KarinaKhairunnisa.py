# -*- coding: utf-8 -*-
"""Final project kalbe_Machine Learning _Karina Khairunnisa.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wtr0Y-iD-JaED_VCuTf7CjmwfRF5CYep
"""

#Library import statements
import pandas as pd
import numpy as np

import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn import preprocessing
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.holtwinters import SimpleExpSmoothing, Holt
from statsmodels.tsa.arima.model import ARIMA
from pandas.plotting import autocorrelation_plot

import warnings

customer_data = pd.read_csv('Case Study - Customer.csv')
product_data = pd.read_csv('Case Study - Product.csv')
store_data = pd.read_csv('Case Study - Store.csv')
transaction_data = pd.read_csv('Case Study - Transaction.csv')

#menampilkan bentuk (shape) dari empat dataframe yang berbeda
customer_data.shape, product_data.shape, store_data.shape, transaction_data.shape

customer_data.head()

product_data.head()

transaction_data.head()

store_data.head()

#data cleansing customer_data
customer_data['Income'] = customer_data['Income'].replace('[,]','.', regex = True).astype('float')

#data cleansing store_data
store_data['Latitude'] = store_data['Latitude'].replace('[,]','.', regex = True).astype('float')
customer_data['Longitude'] = store_data['Longitude'].replace('[,]','.', regex = True).astype('float')

#data cleansing transaction_data
transaction_data['Date'] = pd.to_datetime(transaction_data['Date'])

#menghitung berapa kali setiap nilai yang unik muncul dalam kolom 'TransactionID' dalam dataframe transaction_data
transaction_data['TransactionID'].value_counts()

transaction_data [transaction_data['TransactionID'] == 'TR71313']

"""**Gabung Data**"""

merge_data = pd.merge(transaction_data, customer_data, on = ['CustomerID'])
merge_data = pd.merge(merge_data, product_data.drop(columns = ['Price']), on = ['ProductID'])
merge_data = pd.merge(merge_data, store_data, on = ['StoreID'])

merge_data.head()

#menyimpan data cleansed
merge_data.to_csv('cleaned_data.csv', index=False)

cleaned_data = pd.read_csv('cleaned_data.csv')

"""# **Model Machine Learning Regression (Time Series)**"""

#melakukan agregasi data
regresi_data = merge_data.groupby(['Date']).agg({
    'Qty' :'sum'
}).reset_index()

regresi_data

#digunakan untuk menghasilkan tiga subplot dalam satu gambar, masing-masing mewakili komponen utama dari analisis dekomposisi musiman pada data time series
decomposed = seasonal_decompose(regresi_data.set_index('Date'))

plt.figure(figsize = (8,8))

plt.subplot(311)
decomposed.trend.plot(ax = plt.gca())
plt.title('Trend')
plt.subplot(312)
decomposed.seasonal.plot(ax = plt.gca())
plt.title('Seasonality')
plt.subplot(313)
decomposed.resid.plot(ax = plt.gca())
plt.title('Residuals')

plt.tight_layout()

#untuk membagi data time series menjadi dua set: set pelatihan (train) dan set pengujian (test)
cut_off = round(regresi_data.shape[0]*0.8)
train_df = regresi_data[:cut_off]
test_df = regresi_data[cut_off:].reset_index(drop=True)
train_df.shape, test_df.shape

train_df

test_df

#membuat plot garis menggunakan library seaborn untuk memvisualisasikan data dalam set pelatihan (train) dan set pengujian (test) dari time series.
plt.figure(figsize=(20,5))
sns.lineplot(data=train_df, x=train_df['Date'], y=train_df['Qty']);
sns.lineplot(data=test_df, x=test_df['Date'], y=test_df['Qty']);

#mengilustrasikan seberapa berkorelasinya suatu variabel dengan dirinya sendiri pada pergeseran waktu yang berbeda (lag).
autocorrelation_plot(regresi_data['Qty']);

#untuk mengambil baris-baris dari dataframe customer_data di mana kolom 'Marital Status' memiliki nilai yang kosong
customer_data[customer_data['Marital Status'].isnull()]

#mengambil baris-baris dari dataframe merge_data di mana kolom 'Marital Status' memiliki nilai yang kosong
merge_data[merge_data['Marital Status'].isnull()]

#menghitung dan mengevaluasi kinerja model prediksi menggunakan metrik MAE dan RMSE dengan menggunakan contoh data aktual dan prediksi.
def rmse(y_actual, y_pred):
    mse = mean_squared_error(y_actual, y_pred)
    rmse_value = mse ** 0.5
    return rmse_value


def eval(y_actual, y_pred):
    mae_value = mean_absolute_error(y_actual, y_pred)
    rmse_value = rmse(y_actual, y_pred)
    print(f'Nilai MAE: {mae_value}')
    print(f'Nilai RMSE: {rmse_value}')

y_actual = [3, 5, 7, 9]
y_pred = [2.8, 5.2, 6.6, 9.3]

eval(y_actual, y_pred)

"""# **Metode time series ARIMA**"""

#mencetak informasi tentang kolom-kolom dan beberapa baris pertama dari dataframe train_df dan test_df
print(train_df.columns)
print(test_df.columns)

print(train_df.head())
print(test_df.head())

#membangun model ARIMA, membuat prediksi, mengevaluasi performa prediksi, dan membuat plot visualisasi dari hasil prediksi

y = train_df['Qty']

ARIMAmodel = ARIMA(y, order=(40, 2, 1))
ARIMAmodel_fit = ARIMAmodel.fit()

y_pred = ARIMAmodel_fit.get_forecast(steps=len(test_df))

y_pred_df = y_pred.conf_int()
y_pred_df['predictions'] = ARIMAmodel_fit.predict(start=y_pred_df.index[0], end=y_pred_df.index[-1])
y_pred_out = y_pred_df['predictions']
eval(test_df['Qty'], y_pred_out)

plt.figure(figsize=(20, 5))
plt.plot(train_df['Qty'])
plt.plot(test_df['Qty'], color='green')
plt.plot(y_pred_out, color='brown', label='ARIMA Predictions')
plt.legend()
plt.show()

"""# **-- Model Machine Learning Clustering --**"""

#menampilkan lima baris pertama dari dataframe merge_data
merge_data.head()

#menghitung dan menampilkan matriks korelasi antar kolom-kolom dalam dataframe
merge_data.corr()

#membuat fitur untuk clustering
cluster_df = merge_data.groupby('CustomerID').agg({
    'TransactionID': 'count',
    'Qty' : 'sum',
    'TotalAmount' : 'sum'
}).reset_index()

cluster_df.head()

cluster_df

#pra-pemrosesan data sebelum dilakukan analisis klasterisasi (clustering)
cluster_data = cluster_df.drop(columns = ['CustomerID'])

cluster_data_normalize = preprocessing.normalize(cluster_data)

#menampilkan data yang sudah dinormalisasi.
cluster_data_normalize

#algoritma K-Means untuk melakukan analisis klasterisasi pada data yang telah dinormalisasi.
K = range(2,8)
fits = []
score = []

for k in K:
  model = KMeans(n_clusters = k, random_state = 0, n_init = 'auto').fit(cluster_data_normalize)
  fits.append(model)
  score.append(silhouette_score(cluster_data_normalize, model.labels_, metric = 'euclidean'))

#memvisualisasikan bagaimana nilai silhouette score berubah seiring dengan jumlah klaster yang berbeda
sns.lineplot(x=K, y=score);

fits[1]

#menambahkan kolom 'cluster_label' ke dalam dataframe cluster_df yang berisi label klaster hasil dari analisis K-Means
cluster_df['cluster_label'] = fits[2].labels_

#melakukan agregasi statistik pada dataframe cluster_df
cluster_df.groupby('cluster_label').agg({
    'CustomerID': 'count',
    'TransactionID' : 'mean',
    'Qty' : 'mean'
})

# Memvisualisasikan hasil siluet untuk menentukan jumlah cluster yang optimal
plt.figure(figsize=(10, 6))
plt.plot(K, score, 'bx-')
plt.xlabel('Jumlah Cluster (k)')
plt.ylabel('Skor Silhouette')
plt.title('Metode Elbow untuk Menentukan Jumlah Cluster Optimal')
plt.show()

# Pilih jumlah cluster berdasarkan hasil visualisasi siluet
selected_k = 3
selected_model = fits[selected_k - 2]  # Indeks array dimulai dari 0

# Tambahkan informasi klaster ke dalam DataFrame cluster_df
cluster_df['cluster_label'] = selected_model.labels_

#analisis klasterisasi
cluster_analysis = cluster_df.groupby('cluster_label').agg({
    'CustomerID': 'count',
    'TransactionID': 'mean',
    'Qty': 'mean',
    'TotalAmount': 'mean'
})

# Memberikan rekomendasi berdasarkan analisis klaster
for cluster_label, data in cluster_analysis.iterrows():
    print(f"Cluster {cluster_label}:")
    print(f"Jumlah Pelanggan: {data['CustomerID']}")
    print(f"Rata-rata Transaksi per Pelanggan: {data['TransactionID']:.2f}")
    print(f"Rata-rata Kuantitas Produk per Pelanggan: {data['Qty']:.2f}")
    print(f"Rata-rata Total Pembelian per Pelanggan: {data['TotalAmount']:.2f}")
    print("\n")

# Visualisasi klaster dengan scatter plot
sns.scatterplot(data=cluster_df, x='Qty', y='TotalAmount', hue='cluster_label', palette='Set1')
plt.xlabel('Kuantitas Produk')
plt.ylabel('Total Pembelian')
plt.title('Pengelompokan Pelanggan Berdasarkan Kuantitas Produk dan Total Pembelian')
plt.show()